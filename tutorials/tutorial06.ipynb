{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE9010: Introduction to Data Analysis\n",
    "## Semester 2 2018/19\n",
    "## Xavier Bresson\n",
    "<hr>\n",
    "\n",
    "## Tutorial 6: Bias vs. variance\n",
    "## Objectives\n",
    "### $\\bullet$ Plot loss/error w.r.t. learning capacity, regularization and training size\n",
    "### $\\bullet$ Explore results\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# math library\n",
    "import numpy as np\n",
    "\n",
    "# visualization library\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png2x','pdf')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn library\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# scientific computing library\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# remove warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
    "\n",
    "# computational time\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions of all functions\n",
    "\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(z):\n",
    "    sigmoid_f = 1 / (1 + np.exp(-z)) \n",
    "    return sigmoid_f \n",
    "\n",
    "\n",
    "# predictive function definition\n",
    "def f_pred(X,w): \n",
    "    p = sigmoid(X.dot(w)) \n",
    "    return p\n",
    "\n",
    "\n",
    "# loss function definition\n",
    "def loss_logreg(w,X,y,reg): \n",
    "    n = len(y)\n",
    "    y_pred = sigmoid(X.dot(w)) \n",
    "    loss = -1/n* ( y.T.dot(np.log(y_pred+1e-10)) + (1-y).T.dot(np.log(1-y_pred+1e-10)) ) \n",
    "    d = w.shape[0]\n",
    "    loss += reg/d * w.T.dot(w)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def plot_classes(data,title,cpt_fig):\n",
    "    \n",
    "    # plot\n",
    "    x1 = data[:,0] # feature 1\n",
    "    x2 = data[:,1] # feature 2\n",
    "    idx_class0 = (data[:,2]==0) # index of class0\n",
    "    idx_class1 = (data[:,2]==1) # index of class1\n",
    "\n",
    "    plt.figure(cpt_fig,figsize=(6,6))\n",
    "    plt.scatter(x1[idx_class0], x2[idx_class0], s=60, c='r', marker='+', label='Class0') \n",
    "    plt.scatter(x1[idx_class1], x2[idx_class1], s=30, c='b', marker='o', label='Class1')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def compute_w_solution(X,y,reg):\n",
    "    initial_w = np.zeros((X.shape[1],1))\n",
    "    result = minimize(loss_logreg, initial_w, args=(X,y,reg), method='Powell', options={'maxiter':500})\n",
    "    w_solution = np.array(result.x)[:,None]\n",
    "    loss_solution = loss_logreg(w_solution,X,y,reg)\n",
    "    return w_solution, loss_solution\n",
    "    \n",
    "    \n",
    "def plot_decision_boundary(X,w,data,title,cpt_fig):\n",
    "\n",
    "    # compute values p(x) for multiple data points x\n",
    "    x1_min, x1_max = X[:,1].min(), X[:,1].max() # min and max of grade 1\n",
    "    x2_min, x2_max = X[:,2].min(), X[:,2].max() # min and max of grade 2\n",
    "    xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max)) # create meshgrid\n",
    "\n",
    "    n_mesh = xx1.reshape(-1).shape[0]\n",
    "    mesh_data = np.zeros((n_mesh,2))\n",
    "    mesh_data[:,0] = xx1.reshape(-1)\n",
    "    mesh_data[:,1] = xx2.reshape(-1)\n",
    "    mesh_X = poly.fit_transform(mesh_data)\n",
    "\n",
    "    p = f_pred(mesh_X,w)\n",
    "    p = p.reshape(xx1.shape)\n",
    "\n",
    "    # plot\n",
    "    x1 = data[:,0] # feature 1\n",
    "    x2 = data[:,1] # feature 2\n",
    "    idx_class0 = (data[:,2]==0) # index of class0\n",
    "    idx_class1 = (data[:,2]==1) # index of class1\n",
    "    plt.figure(cpt_fig,figsize=(6,6))\n",
    "    plt.scatter(x1[idx_class0], x2[idx_class0], s=60, c='r', marker='+', label='Class0') \n",
    "    plt.scatter(x1[idx_class1], x2[idx_class1], s=30, c='b', marker='o', label='Class1')\n",
    "    plt.contour(xx1, xx2, p, [0.5], linewidths=2, colors='k') \n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# error\n",
    "def compute_error(X,w,y):\n",
    "    \n",
    "    # continuous predictive function of the classes\n",
    "    pred = f_pred(X,w)\n",
    "    \n",
    "    # discrete predictive function of the classes\n",
    "    y_pred = (pred >= 0.5).astype('int').squeeze()\n",
    "\n",
    "    # accuracy\n",
    "    y = y.squeeze()\n",
    "    diff = (y_pred == y).astype('int')\n",
    "    accuracy = 100* sum(diff)/ y.shape[0]\n",
    "    \n",
    "    return 100-accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Study of error w.r.t. learning capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load train and val datasets\n",
    "<hr>\n",
    "The data features for each data $i$ are $x_i=(x_{i(1)},x_{i(2)})$. <br>\n",
    "The data label, $y_i$, indicates two classes with value 0 or 1.\n",
    "\n",
    "Plot the data points.<br>\n",
    "Hint: You may use `plot_classes` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "train_data = np.loadtxt('data/two_moons_train_set_d_reg.txt', delimiter=',')\n",
    "val_data = np.loadtxt('data/two_moons_val_set_d_reg.txt', delimiter=',')\n",
    "\n",
    "# plot\n",
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Compute the accuracy of the train set using a logistic regression function with a polynomial degree d=6.\n",
    "<hr>\n",
    "\n",
    "Hints: \n",
    "\n",
    "1) You may use the function `PolynomialFeatures` from sklearn library to automatically construct $X$. The function `PolynomialFeatures` generates a matrix consisting of all polynomial combinations of the features with degree less than or equal to $d$. Description of the function is given here:<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html<br>\n",
    "\n",
    "Usage example: <br>\n",
    "$\\hspace{1cm}$ `from sklearn.preprocessing import PolynomialFeatures`<br>\n",
    "$\\hspace{1cm}$ `d = 1 # d=polynomial degree, here d=1 for linear features`<br>\n",
    "$\\hspace{1cm}$ `poly = PolynomialFeatures(d)`<br>\n",
    "$\\hspace{1cm}$ `X = poly.fit_transform(data[:,0:2])`<br>\n",
    "\n",
    "\n",
    "2) You may use the function `compute_w_solution` defined above to find the $w$ solution that optimizes the logistic regression loss.\n",
    "\n",
    "3) You may use the function `compute_error` defined above to compute the error of the logistic regression function.\n",
    "\n",
    "4) You should find a very low error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data features\n",
    "d = 6\n",
    "poly = PolynomialFeatures(d)\n",
    "train_X = poly.fit_transform(train_data[:,0:2])\n",
    "print(train_X.shape)\n",
    "\n",
    "# data label\n",
    "train_y = train_data[:,2][:,None] \n",
    "\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Compute the accuracy of the validation set using the logistic regression function with a polynomial degree d=6 trained on the above training set.\n",
    "<hr>\n",
    "\n",
    "Do you think the validation error will be (almost) zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = poly.fit_transform(val_data[:,0:2])\n",
    "val_y = val_data[:,2][:,None]\n",
    "\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Plot the errors of the train and validation sets w.r.t. learning capacity $d=1,...,9$.\n",
    "<hr>\n",
    "\n",
    "Try to understand the shapes of these learning curves. Refer to slide #24 in  *CE9010_lecture07_developing_data_science_projects*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values of the polynomial degree d\n",
    "list_d = list(range(1,10))\n",
    "\n",
    "train_error_tab = np.zeros(len(list_d))\n",
    "val_error_tab = np.zeros(len(list_d))\n",
    "\n",
    "for i,d in enumerate(list_d):\n",
    "    \n",
    "    poly = PolynomialFeatures(d)\n",
    "    \n",
    "    train_X = #YOUR CODE HERE\n",
    "    train_w_solution, train_loss_solution = #YOUR CODE HERE\n",
    "    train_error = #YOUR CODE HERE\n",
    "    train_error_tab[i] = train_error\n",
    "    \n",
    "    val_X = #YOUR CODE HERE\n",
    "    val_error = #YOUR CODE HERE\n",
    "    val_error_tab[i] = val_error\n",
    "\n",
    "    \n",
    "# plot\n",
    "x = list_d\n",
    "plt.figure(1)\n",
    "plt.plot(x, train_error_tab,label='Train error'.format(i=1))\n",
    "plt.plot(x, val_error_tab,label='Val error'.format(i=2))\n",
    "plt.legend(loc='best')\n",
    "plt.title('Error w.r.t. d (capacity)')\n",
    "plt.xlabel('d')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Study of error w.r.t. regularization\n",
    "\n",
    "## Plot the errors of the train and validation sets w.r.t. regularization parameter $\\lambda$=1e-6,1e-5,..,1e3.\n",
    "<hr>\n",
    "\n",
    "Try to understand the shapes of these learning curves. Refer to slide #26 in  *CE9010_lecture07_developing_data_science_projects*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "train_data = np.loadtxt('data/two_moons_train_set_d_reg.txt', delimiter=',')\n",
    "val_data = np.loadtxt('data/two_moons_val_set_d_reg.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values of the regularization parameter λ\n",
    "reg = np.array(range(-6,4),np.float32)\n",
    "reg = 10**reg\n",
    "list_reg = list(reg)\n",
    "\n",
    "d = 10\n",
    "poly = PolynomialFeatures(d)\n",
    "\n",
    "train_y = train_data[:,2][:,None] \n",
    "val_y = val_data[:,2][:,None]\n",
    "\n",
    "train_error_tab = np.zeros(len(list_reg))\n",
    "val_error_tab = np.zeros(len(list_reg))\n",
    "\n",
    "for i,reg in enumerate(list_reg):\n",
    "    \n",
    "    train_X = #YOUR CODE HERE\n",
    "    train_w_solution, train_loss_solution = #YOUR CODE HERE\n",
    "    train_error = #YOUR CODE HERE\n",
    "    train_error_tab[i] = train_error\n",
    "    \n",
    "    val_X = #YOUR CODE HERE\n",
    "    val_error = #YOUR CODE HERE\n",
    "    val_error_tab[i] = val_error\n",
    "\n",
    "    \n",
    "# plot\n",
    "x = np.log(list_reg)\n",
    "plt.figure(1)\n",
    "plt.plot(x, train_error_tab,label='Train error'.format(i=1))\n",
    "plt.plot(x, val_error_tab,label='Val error'.format(i=2))\n",
    "plt.legend(loc='best')\n",
    "plt.title('Error w.r.t. regularization')\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Study of error w.r.t. training size\n",
    "\n",
    "## 3.1 Plot the errors of the train and validation sets w.r.t. the number of training data n=10,30,50,..490  for a low learning capacity d=1.\n",
    "<hr>\n",
    "\n",
    "Try to understand the shapes of these learning curves. Refer to slide #27 in  *CE9010_lecture07_developing_data_science_projects*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "train_data = np.loadtxt('data/two_moons_train_set_n.txt', delimiter=',')\n",
    "val_data = np.loadtxt('data/two_moons_val_set_n.txt', delimiter=',')\n",
    "\n",
    "train_data_original = train_data\n",
    "val_data_original = val_data\n",
    "n_original = train_data_original.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of values of n\n",
    "list_n = list(np.array(range(10,500,20),np.float32))\n",
    "print(list_n)\n",
    "\n",
    "d = 1\n",
    "poly = PolynomialFeatures(d)\n",
    "\n",
    "train_error_tab = np.zeros(len(list_n))\n",
    "val_error_tab = np.zeros(len(list_n))\n",
    "\n",
    "train_y_original = train_data_original[:,2][:,None] \n",
    "val_y_original = val_data_original[:,2][:,None]\n",
    "\n",
    "for i,n in enumerate(list_n):\n",
    "    \n",
    "     # select sub-set of n data \n",
    "    idx = np.random.permutation(range(n_original))\n",
    "    idx = idx[:int(n)]\n",
    "    train_data = train_data_original[idx,:]\n",
    "    train_y = train_y_original[idx]\n",
    "    val_data = val_data_original[idx,:]\n",
    "    val_y = val_y_original[idx]\n",
    "    \n",
    "    train_X = #YOUR CODE HERE\n",
    "    train_w_solution, train_loss_solution = #YOUR CODE HERE\n",
    "    train_error = #YOUR CODE HERE\n",
    "    train_error_tab[i] = train_error\n",
    "    \n",
    "    val_X = #YOUR CODE HERE\n",
    "    val_error = #YOUR CODE HERE\n",
    "    val_error_tab[i] = val_error\n",
    "\n",
    "    \n",
    "# plot\n",
    "x = list_n\n",
    "plt.figure(1)\n",
    "plt.plot(x, train_error_tab,label='Train error'.format(i=1))\n",
    "plt.plot(x, val_error_tab,label='Val error'.format(i=2))\n",
    "plt.legend(loc='best')\n",
    "plt.title('Error w.r.t. n')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Error')\n",
    "plt.ylim([0,35])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.2 Plot the errors of the train and validation sets w.r.t. the number of training data n=10,30,50,..490  for a low learning capacity d=4.\n",
    "<hr>\n",
    "\n",
    "Try to understand the shapes of these learning curves. Refer to slide #28 in  *CE9010_lecture07_developing_data_science_projects*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List of values of n\n",
    "list_n = list(np.array(range(10,500,20),np.float32))\n",
    "#print(list_n)\n",
    "\n",
    "d = 4\n",
    "poly = PolynomialFeatures(d)\n",
    "\n",
    "train_error_tab = np.zeros(len(list_n))\n",
    "val_error_tab = np.zeros(len(list_n))\n",
    "\n",
    "train_y_original = train_data_original[:,2][:,None] \n",
    "val_y_original = val_data_original[:,2][:,None]\n",
    "\n",
    "for i,n in enumerate(list_n):\n",
    "    \n",
    "     # select sub-set of n data \n",
    "    idx = np.random.permutation(range(n_original))\n",
    "    idx = idx[:int(n)]\n",
    "    train_data = train_data_original[idx,:]\n",
    "    train_y = train_y_original[idx]\n",
    "    val_data = val_data_original[idx,:]\n",
    "    val_y = val_y_original[idx]\n",
    "    \n",
    "    train_X = #YOUR CODE HERE\n",
    "    train_w_solution, train_loss_solution = #YOUR CODE HERE\n",
    "    train_error = #YOUR CODE HERE\n",
    "    train_error_tab[i] = train_error\n",
    "    \n",
    "    val_X = #YOUR CODE HERE\n",
    "    val_error = #YOUR CODE HERE\n",
    "    val_error_tab[i] = val_error\n",
    "\n",
    "    \n",
    "# plot\n",
    "x = list_n\n",
    "plt.figure(1)\n",
    "plt.plot(x, train_error_tab,label='Train error'.format(i=1))\n",
    "plt.plot(x, val_error_tab,label='Val error'.format(i=2))\n",
    "plt.legend(loc='best')\n",
    "plt.title('Error w.r.t. n')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Error')\n",
    "plt.ylim([0,35])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
